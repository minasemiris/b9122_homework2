{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11e26580",
   "metadata": {},
   "source": [
    "## Homework 2 Workings - Minas Emiris\n",
    "\n",
    "Write web crawlers for the following two tasks:\n",
    "1. Extract at least 10 United Nations press releases containing the word “crisis”. Start with the following seed url: https://press.un.org/en. Notice how press release pages gave the \"PRESS RELEASE\" relative link in the top left corner. Here is an example press release: https://press.un.org/en/2023/sc15431.doc.htm where the “PRESS RELEASE” has the following relative anchor tag:\n",
    "`<a href=\"/en/press-release\" hreflang=\"en\">Press Release</a>`\n",
    "Use this information to determine whether the web page is a press release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0614cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://press.un.org/en'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "243322e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://press.un.org/en/2023/gadis3715.doc.htm\n",
      "https://press.un.org/en/2023/gaef3589.doc.htm\n",
      "https://press.un.org/en/2023/gal3689.doc.htm\n",
      "https://press.un.org/en/2023/gaab4429.doc.htm\n",
      "https://press.un.org/en/2023/sc15435.doc.htm\n",
      "https://press.un.org/en/2023/gashc4380.doc.htm\n",
      "https://press.un.org/en/2023/ga12543.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21989.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21988.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21987.doc.htm\n",
      "https://press.un.org/en/2023/sc15436.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21986.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21985.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21983.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21984.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21982.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21981.doc.htm\n",
      "https://press.un.org/en/2023/ga12487.doc.htm\n",
      "https://press.un.org/en/2023/sc15172.doc.htm\n",
      "https://press.un.org/en/2023/db231011.doc.htm\n",
      "https://press.un.org/en/2023/231002_sc.doc.htm\n"
     ]
    }
   ],
   "source": [
    "# Initialize Soup object\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Initialize the press release holding object\n",
    "press_releases = []\n",
    "\n",
    "# Loop over anchor tags\n",
    "for link in soup.find_all('a', href=True):\n",
    "    href = link['href']\n",
    "    \n",
    "    # Upon checking links, the pattern realized is that /en/ is followed year + .doc.htm.\n",
    "    if '/en/2023' in href and href.endswith('.doc.htm'):\n",
    "        full_url = href if href.startswith('http') else 'https://press.un.org' + href\n",
    "        \n",
    "        # Add to press_releases if not already present\n",
    "        if full_url not in press_releases:\n",
    "            press_releases.append(full_url)\n",
    "\n",
    "# Display the results\n",
    "for release in press_releases:\n",
    "    print(release)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35615bb3",
   "metadata": {},
   "source": [
    "2. Crawl the press room of the European Parliament and extract at least 10 press releases that cover the plenary sessions and contain the word “crisis”. Start with the following seed url: https://www.europarl.europa.eu/news/en/press-room Notice how press releases related to plenary sessions contain the text “PLENARY SESSIONS” with the following html: `<span class=\"ep_name\">Plenary session</span>` \n",
    "Here is an example:\n",
    "https://www.europarl.europa.eu/news/en/press-room/20220620IPR33417/national-recovery-plans-meps-assess-the-performance-of-crisis-funding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "60fe7f0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parliament’s Special Committee on the COVID-19 pandemic has adopted recommendations to improve EU crisis management and preparedness for future health emergencies. \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.europarl.europa.eu/news/en/press-room'\n",
    "press_releases = []\n",
    "\n",
    "def extract_press_releases(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Look for the container holding the articles\n",
    "    gridrow_content = soup.find('div', class_='ep_gridcolumn-content')\n",
    "    \n",
    "    # Assuming each article is within a <div>\n",
    "    for article_div in gridrow_content.find_all('div', recursive=False):\n",
    "        content = article_div.get_text()\n",
    "        if 'crisis' in content.lower():\n",
    "            press_releases.append(content)\n",
    "\n",
    "# Start by scraping the first page\n",
    "extract_press_releases(url)\n",
    "P1 = 1\n",
    "max_pages = 50\n",
    "\n",
    "while len(press_releases) < 10 and P1 <= max_pages:\n",
    "    P1 += 1\n",
    "    next_url = f\"{url}/page/{P1}\"  # Assuming the structure is like this\n",
    "    extract_press_releases(next_url)\n",
    "\n",
    "# Print the collected press releases\n",
    "for articles in press_releases:\n",
    "    print(articles)\n",
    "    print('-' * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f065fe9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4df09408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the Load More button or another error occurred: Message: element click intercepted: Element <div id=\"continuesLoading_buttonLine\" class=\"ep_gridcolumn ep-m_footer\" data-view1200=\"8\" data-view1020=\"8\" data-view750=\"12\" data-view640=\"8\" data-view480=\"8\" data-view320=\"4\">...</div> is not clickable at point (396, 665). Other element would receive the click: <p>...</p>\n",
      "  (Session info: chrome=117.0.5938.149)\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x00000001005cad68 chromedriver + 4337000\n",
      "1   chromedriver                        0x00000001005c2de4 chromedriver + 4304356\n",
      "2   chromedriver                        0x00000001001efa5c chromedriver + 293468\n",
      "3   chromedriver                        0x000000010023b75c chromedriver + 603996\n",
      "4   chromedriver                        0x0000000100239824 chromedriver + 596004\n",
      "5   chromedriver                        0x000000010023744c chromedriver + 586828\n",
      "6   chromedriver                        0x00000001002364c4 chromedriver + 582852\n",
      "7   chromedriver                        0x000000010022a938 chromedriver + 534840\n",
      "8   chromedriver                        0x000000010022a200 chromedriver + 532992\n",
      "9   chromedriver                        0x000000010026f908 chromedriver + 817416\n",
      "10  chromedriver                        0x0000000100228a5c chromedriver + 526940\n",
      "11  chromedriver                        0x0000000100229908 chromedriver + 530696\n",
      "12  chromedriver                        0x0000000100590db4 chromedriver + 4099508\n",
      "13  chromedriver                        0x0000000100595270 chromedriver + 4117104\n",
      "14  chromedriver                        0x000000010059b4fc chromedriver + 4142332\n",
      "15  chromedriver                        0x0000000100595d70 chromedriver + 4119920\n",
      "16  chromedriver                        0x000000010056da44 chromedriver + 3955268\n",
      "17  chromedriver                        0x00000001005b2a18 chromedriver + 4237848\n",
      "18  chromedriver                        0x00000001005b2b94 chromedriver + 4238228\n",
      "19  chromedriver                        0x00000001005c2a5c chromedriver + 4303452\n",
      "20  libsystem_pthread.dylib             0x00000001a6ff7fa8 _pthread_start + 148\n",
      "21  libsystem_pthread.dylib             0x00000001a6ff2da0 thread_start + 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Initialize the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "URL = 'https://www.europarl.europa.eu/news/en/press-room'\n",
    "driver.get(URL)\n",
    "\n",
    "MAX_CLICKS = 10\n",
    "\n",
    "\n",
    "# copied code from online.\n",
    "for _ in range(MAX_CLICKS):\n",
    "    try:\n",
    "        load_more_button = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, 'continuesLoading_buttonLine'))\n",
    "        )\n",
    "        load_more_button.click()\n",
    "    except Exception as e:\n",
    "        print(\"Could not find the Load More button or another error occurred:\", e)\n",
    "        break\n",
    "# until here.\n",
    "        \n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "driver.quit()\n",
    "\n",
    "press_releases = []\n",
    "\n",
    "gridrow_content = soup.find('div', class_='ep_gridcolumn-content')\n",
    "for article_div in gridrow_content.find_all('div', recursive=False):\n",
    "    content = article_div.get_text()\n",
    "    if 'crisis' in content.lower():\n",
    "        press_releases.append(content.strip())\n",
    "\n",
    "for article in press_releases:\n",
    "    print(article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b982b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dab76d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
